{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"./round-1-island-data-bottle/prices_round_1_day_-2.csv\",\n",
    "         \"./round-1-island-data-bottle/prices_round_1_day_-1.csv\",\n",
    "         \"./round-1-island-data-bottle/prices_round_1_day_0.csv\",\n",
    "         ]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in files:\n",
    "    tmp_df = pd.read_csv(file, sep=';')\n",
    "    dfs.append(tmp_df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df[\"global_timestamp\"] = (df[\"day\"] + 2) * 1_000_000 + df[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"global_timestamp\", inplace=True)\n",
    "\n",
    "df.drop(columns=[\"day\", \"mid_price\", \"profit_and_loss\", \"timestamp\"], inplace = True, errors = \"ignore\")\n",
    "\n",
    "bid_cols = [col for col in df.columns if col.startswith(\"bid_price_\")]\n",
    "ask_cols = [col for col in df.columns if col.startswith(\"ask_price_\")]\n",
    "\n",
    "def get_lowest_bid(row):\n",
    "    bids = [row[b] for b in bid_cols if pd.notnull(row[b])]\n",
    "    if not bids:\n",
    "        return None\n",
    "    return min(bids)\n",
    "\n",
    "def get_highest_ask(row):\n",
    "    asks = [row[a] for a in ask_cols if pd.notnull(row[a])]\n",
    "    if not asks:\n",
    "        return None\n",
    "    return max(asks)\n",
    "\n",
    "df[\"lowest_bid\"] = df.apply(get_lowest_bid, axis=1)\n",
    "df[\"highest_ask\"] = df.apply(get_highest_ask, axis=1)\n",
    "df[\"fair_value\"] = (df[\"lowest_bid\"] + df[\"highest_ask\"]) / 2.0\n",
    "\n",
    "df_kelp = df[df[\"product\"] == \"KELP\"].copy()\n",
    "df_squid = df[df[\"product\"] == \"SQUID_INK\"].copy()\n",
    "\n",
    "mean_kelp = df_kelp[\"fair_value\"].mean()\n",
    "mean_squid = df_squid[\"fair_value\"].mean()\n",
    "std_kelp = df_kelp[\"fair_value\"].std()\n",
    "std_squid = df_squid[\"fair_value\"].std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P test for random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kelp.sort_values(by=\"global_timestamp\", inplace=True)\n",
    "df_squid.sort_values(by=\"global_timestamp\", inplace=True)\n",
    "\n",
    "# Get the fair_value as a numpy array (dropping missing values)\n",
    "kelp_values = df_kelp[\"fair_value\"].dropna().values\n",
    "squid_values = df_squid[\"fair_value\"].dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF (Augmented Dickey-Fuller) test\n",
    "def run_adf_test(timeseries, label):\n",
    "    result = adfuller(timeseries, autolag=\"AIC\")\n",
    "    adf_statistic = result[0]\n",
    "    p_value = result[1]\n",
    "    used_lag = result[2]\n",
    "    nobs = result[3]\n",
    "\n",
    "    print(f\"\\nADF Test for {label}:\")\n",
    "    print(f\"  ADF Statistic: {adf_statistic:.4f}\")\n",
    "    print(f\"  p-value:       {p_value:.20f}\")\n",
    "    print(f\"  # Lags Used:   {used_lag}\")\n",
    "    print(f\"  # Observations:{nobs}\")\n",
    "    \n",
    "    # Interpretation based on p < 0.05 threshold\n",
    "    p_threshold = 0.05\n",
    "    if p_value < p_threshold:\n",
    "        print(f\"  --> p < {p_threshold} => Reject H0 (random walk), \"\n",
    "              \"suggesting non-random/meaningful pattern.\")\n",
    "    else:\n",
    "        print(f\"  --> p >= {p_threshold} => Fail to Reject H0 (random walk), \"\n",
    "              \"suggesting random/walk-like behavior.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p value is the chance of seeing data like this if the series really were a random walk.\n",
    "run_adf_test(kelp_values, \"KELP\")\n",
    "run_adf_test(squid_values, \"SQUID_INK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Ljung-Box Test\n",
    "def run_ljung_box_test(timeseries, label, lags=10):\n",
    "    # The 'lags' parameter is somewhat arbitrary; you can experiment with it.\n",
    "    lb_result = acorr_ljungbox(timeseries, lags=[lags], return_df=True)\n",
    "    p_value = lb_result[\"lb_pvalue\"].iloc[0]\n",
    "    test_stat = lb_result[\"lb_stat\"].iloc[0]\n",
    "    \n",
    "    print(f\"\\nLjung-Box Test for {label} (lags={lags}):\")\n",
    "    print(f\"  LB Statistic: {test_stat:.4f}\")\n",
    "    print(f\"  p-value:      {p_value:.20f}\")\n",
    "    p_threshold = 0.05\n",
    "    if p_value < p_threshold:\n",
    "        print(f\"  --> p < {p_threshold} => Suggests autocorrelation (non-random).\")\n",
    "    else:\n",
    "        print(f\"  --> p >= {p_threshold} => No strong evidence of autocorrelation (random-like).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ljung_box_test(kelp_values, \"KELP\", lags=10)\n",
    "run_ljung_box_test(squid_values, \"SQUID_INK\", lags=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLANATIONS\n",
    "#High Autocorrelation: Each data point in the series closely depends on previous points—so if yesterday’s price was high, today’s price is likely high too.\n",
    "\n",
    "#Random-Walk-Like (ADF Test): The series doesn’t settle around a constant average but keeps “wandering” over time. The ADF test can’t rule out that the series is drifting randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leading and Lagging Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kelp[\"fair_value\"] = df_kelp[\"fair_value\"] - mean_kelp\n",
    "df_squid[\"fair_value\"] = df_squid[\"fair_value\"] - mean_squid\n",
    "\n",
    "#derek's scaling and alingment that supports the pair trading algorithm\n",
    "df_squid[\"fair_value\"] = (-1 * df_squid[\"fair_value\"]) + 2000\n",
    "df_kelp[\"fair_value\"] = df_kelp[\"fair_value\"] * (std_squid / std_kelp) + 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_kelp[\"global_timestamp\"], df_kelp[\"fair_value\"], label=\"KELP Fair Value\")\n",
    "plt.plot(df_squid[\"global_timestamp\"], df_squid[\"fair_value\"], label=\"SQUID_INK Fair Value\")\n",
    "\n",
    "#plt.axhline(y=2000, label=\"Mean Fair Value\")\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Fair Value\")\n",
    "plt.title(\"KELP vs SQUID_INK Fair Value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_kelp[\"global_timestamp\"], ratio_series, label=\"KELP / SQUID_INK\")\n",
    "\n",
    "plt.axhline(\n",
    "    y=1\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Ratio of Fair Values\")\n",
    "plt.title(\"Ratio: KELP Fair Value / SQUID_INK Fair Value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messing Around for Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df_squid[\"global_timestamp\"], df_squid[\"fair_value\"])\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Fair Value\")\n",
    "plt.title(\"SQUID_INK Fair Value over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df has a 'SQUID_INK' column with price data for each iteration\n",
    "# 1. Calculate returns (price differences)\n",
    "df_squid['returns'] = df_squid[\"fair_value\"].diff()\n",
    "\n",
    "# 2. Drop NaN from the first diff\n",
    "#df_squid_no_start = df_squid[int(len(df) * 0.10):]\n",
    "returns = df_squid['returns'].dropna()\n",
    "# 3. Autocorrelation Plot\n",
    "plt.figure()\n",
    "plot_acf(returns, lags=50)\n",
    "plt.title(\"Autocorrelation of SQUID_INK Returns\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Partial Autocorrelation Plot\n",
    "plt.figure()\n",
    "plot_pacf(returns, lags=50, method='ywm')  # 'ywm' is often stable for financial time series\n",
    "plt.title(\"Partial Autocorrelation of SQUID_INK Returns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "big spike approximates\n",
    "- lag 0 - 1.00\n",
    "- lag 1 - -0.10\n",
    "- lag 2 - -0.07\n",
    "- lag 3 - 0.05\n",
    "- lag 12 - 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same 'returns' from above\n",
    "plt.figure()\n",
    "returns.hist(bins=100)  # Adjust bins as you wish\n",
    "plt.yscale('log')  # Set y-axis to log scale\n",
    "plt.title(\"Distribution of SQUID_INK Returns\")\n",
    "plt.xlabel(\"Return\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "k2, p_value = normaltest(returns.dropna())\n",
    "print(f\"Statistic: {k2}, p-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject null hypothesis of normality (data is likely not normal).\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis of normality (data is likely normal).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating volatitiliy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df_squid[\"global_timestamp\"], df_squid[\"fair_value\"])\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Fair Value\")\n",
    "plt.title(\"SQUID_INK Fair Value over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure fair_value is float\n",
    "df_squid['fair_value'] = df_squid['fair_value'].astype(float)\n",
    "\n",
    "# Use a rolling window (e.g., 30 rows)\n",
    "window = 10\n",
    "df_squid['fair_value_volatility'] = df_squid['fair_value'].rolling(window).std()\n",
    "print(df_squid[['global_timestamp', 'fair_value', 'fair_value_volatility']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum top 3 bid and ask volumes\n",
    "df_squid['total_bid_volume'] = df_squid[['bid_volume_1', 'bid_volume_2', 'bid_volume_3']].sum(axis=1)\n",
    "df_squid['total_ask_volume'] = df_squid[['ask_volume_1', 'ask_volume_2', 'ask_volume_3']].sum(axis=1)\n",
    "\n",
    "# Order book imbalance\n",
    "df_squid['book_imbalance'] = (\n",
    "    df_squid['total_bid_volume'] - df_squid['total_ask_volume']\n",
    ") / (\n",
    "    df_squid['total_bid_volume'] + df_squid['total_ask_volume']\n",
    ")\n",
    "\n",
    "# Rolling volatility of order book imbalance\n",
    "df_squid['imbalance_volatility'] = df_squid['book_imbalance'].rolling(window).std()\n",
    "print(df_squid[['global_timestamp', 'book_imbalance', 'imbalance_volatility']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squid['volatility_score'] = (\n",
    "    0.6 * df_squid['fair_value_volatility'].fillna(0) +\n",
    "    0.4 * df_squid['imbalance_volatility'].fillna(0)\n",
    ")\n",
    "print(df_squid[['global_timestamp', 'fair_value_volatility', 'imbalance_volatility', 'volatility_score']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squid[['fair_value', 'volatility_score']].plot(figsize=(12, 6), secondary_y='volatility_score')\n",
    "plt.title('Fair Value and Volatility Score Over Time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
